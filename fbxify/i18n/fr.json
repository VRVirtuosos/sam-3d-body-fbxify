{
  "app": {
    "title": "SAM 3D Body ‚Üí Unity FBX",
    "heading": "üßç‚Äç‚ôÇÔ∏è SAM 3D Body ‚Üí Unity Humanoid FBX",
    "program_tab": "Programme",
    "about_tab": "√Ä propos",
    "features_title": "Fonctionnalit√©s",
    "features": [
      "G√©n√©rer des fichiers FBX compatibles Unity Humanoid √† partir d'une seule image",
      "G√©n√©rer des animations multi-images √† partir de vid√©os MP4",
      "Maillage 3D + squelette + **animation**"
    ],
    "usage_title": "Utilisation",
    "usage": [
      "Utilisez l‚Äôonglet Estimation de Pose pour t√©l√©charger une image ou une vid√©o MP4",
      "Cliquez sur le bouton \"Estimer la Pose\"",
      "Une fois l‚Äôestimation termin√©e, passez √† l‚Äôonglet G√©n√©rer FBX",
      "(Optionnel) T√©l√©chargez le JSON g√©n√©r√© pour une utilisation future, r√©glage du raffinement, etc.",
      "Cliquez sur le bouton \"G√©n√©rer FBX\"",
      "T√©l√©chargez le FBX g√©n√©r√© ‚Üí Importez dans Unity",
      "Les fonctionnalit√©s suivantes sont optionnelles :",
      "T√©l√©chargez vos propres fichiers de bboxes et d'intrins√®ques de cam√©ra depuis gta-link, boxmot, colmap",
      "Pour la vid√©o, vous pouvez ou non vouloir le mouvement de racine pour votre armature - cochez la case si vous le souhaitez",
      "Appliquez un lissage de style mocap standard √† l'animation via Refinement. Activ√© par d√©faut avec quelques param√®tres personnalisables."
    ]
  },
  "ui": {
    "pose_tab_label": "Estimation de Pose",
    "fbx_tab_label": "G√©n√©rer FBX",
    "profile": "üìä Mod√®le d'Armature",
    "input_file": "üìÅ Fichier Image/Vid√©o",
    "use_bbox": "üë• Utiliser le Fichier BBOX",
    "bbox_file": "üìÅ Fichier BBOX",
    "num_people": "üë• Nombre de Personnes",
    "missing_bbox_behavior": "En Cas d'Image Manquante",
    "missing_bbox_behavior_info": "Que faire lorsque les donn√©es de bbox sont manquantes pour une image : Ex√©cuter la D√©tection (utiliser num_people pour d√©tecter) ou Ignorer l'Image (ignorer l'estimation de pose pour cette image)",
    "tracking": {
      "mode_label": "üß≠ Mode de suivi",
      "mode_info": "Choisissez comment les personnes sont suivies pendant l'estimation",
      "mode_bbox": "Utiliser le Fichier BBOX",
      "mode_count": "Les N personnes les plus proches",
      "mode_inference": "Suivi par inf√©rence",
      "mode_inference_bbox": "Suivi par inf√©rence + Fichier BBOX",
      "config_title": "Configuration du tracking par inf√©rence",
      "enabled": "Activer le tracking",
      "enabled_info": "Active ou d√©sactive le tracking (uniquement en mode Suivi par inf√©rence)",
      "thresholds_title": "Seuils d'association",
      "max_gap_frames": "√âcart maximal entre images",
      "max_gap_frames_info": "√âcart maximal avant de fermer un tracklet",
      "merge_max_gap_frames": "√âcart maximal pour fusion",
      "merge_max_gap_frames_info": "√âcart maximal autoris√© pour fusionner des tracklets",
      "min_tracklet_length": "Longueur minimale du tracklet",
      "min_tracklet_length_info": "Nombre minimal de d√©tections pour conserver un tracklet",
      "min_similarity": "Similarit√© minimale",
      "min_similarity_info": "Similarit√© minimale pour associer des d√©tections",
      "shape_distance_threshold": "Seuil de distance de forme",
      "shape_distance_threshold_info": "Seuil de distance pour shape_params",
      "cam_distance_threshold": "Seuil de distance cam√©ra",
      "cam_distance_threshold_info": "Seuil de distance pour pred_cam_t",
      "min_cam_similarity": "Similarit√© cam min",
      "min_cam_similarity_info": "Rejeter les appariements si la similarit√© cam est sous ce seuil (ex. 0.01 rejette les t√©l√©ports cam=0). Seulement si Utiliser pred_cam_t est activ√©.",
      "min_pose_similarity": "Similarit√© pose min",
      "min_pose_similarity_info": "Rejeter les appariements si la similarit√© pose est sous ce seuil (ex. 0.3 rejette ~30% d'accord). Seulement si Utiliser Pose Aux est activ√©. 0 = pas de seuil.",
      "shape_maturity_frames": "Maturit√© forme (images)",
      "shape_maturity_frames_info": "Faire confiance √† la forme seulement apr√®s ce nombre de d√©tections dans le tracklet. En dessous, apparier sur pose et cam uniquement (re-ID selon l'√¢ge).",
      "high_shape_override_cam": "Forme √©lev√©e prime sur cam",
      "high_shape_override_cam_info": "Quand le tracklet est mature et la similarit√© de forme tr√®s √©lev√©e, autoriser l'appariement m√™me si la cam est faible (m√™me personne r√©apparue ailleurs).",
      "high_shape_threshold": "Seuil forme √©lev√©e",
      "high_shape_threshold_info": "Seuil de similarit√© de forme pour l'override ci-dessus (ex. 0.95).",
      "pose_distance_threshold": "Seuil de distance de pose",
      "pose_distance_threshold_info": "Seuil de distance pour la pose auxiliaire",
      "iou_distance_threshold": "Seuil de distance IoU",
      "iou_distance_threshold_info": "Seuil de distance pour l'IoU des bbox (requiert bbox_xywh)",
      "weights_title": "Poids de similarit√©",
      "shape_weight": "Poids de forme",
      "shape_weight_info": "Poids pour la similarit√© shape_params",
      "cam_weight": "Poids de cam√©ra",
      "cam_weight_info": "Poids pour la similarit√© pred_cam_t",
      "pose_weight": "Poids de pose",
      "pose_weight_info": "Poids pour la similarit√© de pose auxiliaire",
      "iou_weight": "Poids IoU",
      "iou_weight_info": "Poids pour la similarit√© IoU des bbox",
      "features_title": "Fonctionnalit√©s",
      "use_shape_params": "Utiliser shape_params",
      "use_pred_cam_t": "Utiliser pred_cam_t",
      "use_pose_aux": "Utiliser la pose auxiliaire",
      "use_bbox_iou": "Utiliser l'IoU des bbox",
      "export_frame_assignments": "Exporter les assignations par image",
      "export_tracklet_detections": "Exporter les d√©tections de tracklet",
      "export_mot_bboxes": "Exporter MOT BBoxes",
      "bg_title": "Filtrage de l'arri√®re-plan",
      "bg_enabled": "Activer le filtrage de l'arri√®re-plan",
      "bg_enabled_info": "Optionnel : r√©duit les foules/occlusions en arri√®re-plan pendant le suivi par inf√©rence. D√©sactiv√© par d√©faut.",
      "bg_detection_gates_title": "Filtres de d√©tection (par image)",
      "bg_min_bbox_height_px": "Hauteur min. de bbox (px)",
      "bg_min_bbox_height_px_info": "Supprime les d√©tections dont la hauteur de bbox est inf√©rieure √† ce seuil. 0 = d√©sactiv√©.",
      "bg_min_bbox_area_px2": "Aire min. de bbox (px¬≤)",
      "bg_min_bbox_area_px2_info": "Supprime les d√©tections dont l'aire de bbox est inf√©rieure √† ce seuil. 0 = d√©sactiv√©.",
      "bg_depth_max_z": "Profondeur max. z (pred_cam_t)",
      "bg_depth_max_z_info": "Conserve les d√©tections avec pred_cam_t[2] <= ce seuil. 0 = d√©sactiv√©.",
      "bg_keep_nearest_z_quantile": "Conserver le quantile le plus proche (z)",
      "bg_keep_nearest_z_quantile_info": "Par image : conserve la fraction la plus proche selon z (ex. 0.7 conserve les 70% les plus proches). 0 = d√©sactiv√©.",
      "bg_auto_size_title": "Seuil automatique par taille",
      "bg_size_auto_method": "M√©thode automatique par taille",
      "bg_size_auto_method_info": "none/percentile/otsu/gmm2. Utilise la hauteur/aire de bbox. Appliqu√© par image.",
      "bg_size_feature": "Caract√©ristique de taille",
      "bg_size_feature_info": "Quelle mesure de taille de bbox utiliser pour le filtrage par taille.",
      "bg_size_percentile": "Supprimer petit percentile",
      "bg_size_percentile_info": "Pour percentile : supprime la fraction la plus petite (ex. 0.2 supprime les 20% plus petits). 0 = d√©sactiv√©.",
      "bg_tracklet_scoring_title": "Score des tracklets (sujets stables)",
      "bg_tracklet_score_enabled": "Activer le score des tracklets",
      "bg_tracklet_score_enabled_info": "Attribue un score aux tracklets selon stabilit√©/persistance et peut supprimer les tracklets d'arri√®re-plan.",
      "bg_tracklet_score_threshold": "Seuil de score du tracklet",
      "bg_tracklet_score_threshold_info": "Conserve les tracklets avec un score >= seuil. 0 = d√©sactiv√©.",
      "bg_min_tracklet_frames_for_scoring": "Min. d'images pour scorer",
      "bg_min_tracklet_frames_for_scoring_info": "Les tracklets plus courts que ce seuil sont trait√©s comme faible confiance (souvent des occlusions).",
      "bg_w_length": "Poids : dur√©e",
      "bg_w_length_info": "Poids du score de premier plan pour la dur√©e/couverture du tracklet.",
      "bg_w_size": "Poids : taille",
      "bg_w_size_info": "Poids du score de premier plan pour la taille m√©diane de bbox.",
      "bg_w_size_stability": "Poids : stabilit√© de taille",
      "bg_w_size_stability_info": "Poids du score de premier plan pour la stabilit√© de la taille de bbox dans le temps (IQR).",
      "bg_w_centering": "Poids : centrage",
      "bg_w_centering_info": "Poids du score de premier plan pour rester proche du centre du groupe.",
      "bg_auto_roi_title": "ROI automatique (calcul√©)",
      "bg_auto_roi_enabled": "Activer le ROI automatique",
      "bg_auto_roi_enabled_info": "Construit un ROI mobile √† partir des sujets stables pour supprimer les d√©tections d'arri√®re-plan.",
      "bg_auto_roi_window_frames": "Fen√™tre ROI auto (images)",
      "bg_auto_roi_window_frames_info": "Taille de la fen√™tre utilis√©e pour estimer le centre/rayon du ROI.",
      "bg_auto_roi_point": "Point du ROI",
      "bg_auto_roi_point_info": "Utiliser le bas-centre de la bbox (id√©al pour une sc√®ne au sol) ou le centre de la bbox.",
      "bg_auto_roi_mad_k": "Facteur MAD du rayon ROI",
      "bg_auto_roi_mad_k_info": "Rayon = MAD * k (dispersion robuste). Plus √©lev√© = ROI plus grand.",
      "bg_auto_roi_min_radius_px": "Rayon min. ROI (px)",
      "bg_auto_roi_min_radius_px_info": "Rayon minimum pour √©viter un sur-filtrage lorsqu'il y a peu de d√©tections.",
      "bg_auto_roi_smoothing_alpha": "Alpha de lissage du ROI",
      "bg_auto_roi_smoothing_alpha_info": "Lissage EMA du centre/rayon du ROI (0 = aucune mise √† jour, 1 = aucun lissage).",
      "bg_refine_second_pass": "Affinage en seconde passe",
      "bg_refine_second_pass_info": "Si activ√© avec ROI automatique, relance l'association en utilisant le ROI automatique pour r√©duire l'explosion des tracks.",
      "load_config": "Charger la configuration de tracking",
      "save_config_btn": "Enregistrer la configuration de tracking",
      "save_config": "Fichier de configuration de tracking"
    },
    "fov_method": "üì∑ M√©thode d'Estimation FOV",
    "fov_method_info": "Par d√©faut : Int√©gr√©, s'ex√©cute √† chaque image | Fichier : Charger depuis cameras.txt | √âchantillon : Moyenne des images",
    "fov_file": "üìÅ Fichier d'Intrins√®ques de Cam√©ra (COLMAP cameras.txt ou format MoGe)",
    "sample_number": "üìä Nombre d'√âchantillons",
    "sample_number_info": "Nombre d'images √† √©chantillonner et moyenner pour l'estimation FOV",
    "precision": "üéõÔ∏è Pr√©cision",
    "precision_info": "FP32 pour la meilleure qualit√©, BF16/FP16 pour une inf√©rence plus rapide",
    "frame_batch_size": "Taille du lot de trames",
    "frame_batch_size_info": "Ex√©cuter le mod√®le de pose une fois par N trames (1 = par trame). 4 ou 8 peut acc√©l√©rer la vid√©o. Plus √©lev√© = plus de m√©moire GPU.",
    "detection_batch_size": "Taille du lot de d√©tection",
    "detection_batch_size_info": "Sans fichier BBOX : nombre d'images par lot du d√©tecteur (1 = par trame). Plus √©lev√© peut acc√©l√©rer la d√©tection.",
    "auto_run": "‚ö° Ex√©cuter G√©n√©rer FBX Automatiquement (apr√®s l'Estimation de Pose)",
    "use_root_motion": "üß≠ Appliquer le Mouvement de Racine",
    "auto_floor": "üß≠ Auto-sol",
    "auto_floor_info": "D√©cale la hauteur moyenne de pred_cam_t √† 0 pour que les sujets soient au-dessus du sol",
    "include_mesh": "üé≠ Inclure le Maillage",
    "include_extrinsics": "üì∑ Inclure Extrins√®ques",
    "use_personalized_body": "üë§ Utiliser le Corps Personnalis√©",
    "use_personalized_body_info": "G√©n√©rer un maillage de corps personnalis√© √† partir des donn√©es d'estimation. Si d√©coch√©, utilise le corps LOD par d√©faut.",
    "lod": "üìä LOD",
    "lod_info": "Niveau de D√©tail pour le maillage (0-6)",
    "outlier_removal_percent": "üìä Suppression des Valeurs Aberrantes (%)",
    "outlier_removal_percent_info": "Pourcentage de valeurs aberrantes √† supprimer de chaque queue (0-50)",
    "extrinsics_sample_rate": "üìä Taux de Sous-√âchantillonnage des Extrins√®ques",
    "extrinsics_sample_rate_info": "0 = auto (arrondir images / extrins√®ques)",
    "extrinsics_scale": "üìè √âchelle des Extrins√®ques",
    "extrinsics_scale_info": "Met √† l'√©chelle les composantes de translation des extrins√®ques",
    "extrinsics_invert_quaternion": "üîÅ Inverser la Rotation des Extrins√®ques",
    "extrinsics_invert_quaternion_info": "Traite qvec comme cam√©ra‚Üímonde au lieu de monde‚Üícam√©ra",
    "extrinsics_invert_translation": "üîÅ Inverser la Translation des Extrins√®ques",
    "extrinsics_invert_translation_info": "Traite tvec comme cam√©ra‚Üímonde au lieu de monde‚Üícam√©ra",
    "extrinsics_file": "üìÅ Fichier d'Extrins√®ques (COLMAP images.txt)",
    "estimate_pose_btn": "üéØ Estimer la Pose",
    "step_1_estimate_pose": "Estimer la Pose",
    "generate_fbx_btn": "üöÄ G√©n√©rer FBX",
    "step_2_generate_fbx": "G√©n√©rer FBX",
    "options_title": "Options",
    "estimation_options_title": "Options d'Estimation",
    "fbx_options_title": "Options FBX",
    "pose_json_file": "üìÑ Sorties d'estimation de pose",
    "pose_json_file_info": "T√©l√©chargez un fichier JSON d'estimation de pose, ou il sera rempli automatiquement apr√®s l'estimation",
    "output_files": "üì¶ Fichiers G√©n√©r√©s",
    "developer_options": "Options D√©veloppeur",
    "pose_dev": {
      "output_tracking_bbox": "Sortie BBOX de tracking",
      "run_bbox_detection_now": "Exporter la d√©tection en MOT",
      "run_bbox_detection_now_info": "Ex√©cuter la d√©tection sur l'entr√©e actuelle (vid√©o ou image) et enregistrer un fichier MOT. √Ä utiliser avec **BBOX File** pour √©viter de red√©tecter lors de l'estimation.",
      "bbox_detection_output": "Fichier de d√©tection (MOT)",
      "estimation_file_rerun_tracking": "Fichier d'estimation (relancer le tracking)",
      "rerun_tracking_btn": "Relancer le tracking",
      "step_through_console": "Pas √† pas (pause √† chaque frame dans la console)",
      "debug_start_frame": "D√©marrer le d√©bogage √† la frame",
      "debug_start_frame_info": "Index de frame √† partir duquel le pas √† pas et le d√©bogage par frame commencent (0 = d√®s la premi√®re). Utile pour cibler une frame probl√©matique."
    },
    "export_personalized_body_obj": "üß™ Exporter l'OBJ du corps personnalis√©",
    "graph_refinement": "üìà Graphiques de raffinage",
    "create_camera": "üì∑ Cr√©er Cam√©ra",
    "camera_zoom": "üì∑ Zoom Cam√©ra",
    "camera_scene": "üéûÔ∏è Sc√®ne Cam√©ra",
    "cancel_current_jobs": "üõë Annuler les t√¢ches en cours",
    "cancel_current_jobs_info": "Arr√™te l‚Äôestimation ou la g√©n√©ration FBX en cours (queue requis).",
    "pose_cli_generator_title": "CLI d‚ÄôEstimation de Pose",
    "pose_cli_generator_info": "Cr√©e un mod√®le de commande pour l‚Äôestimation de pose. Remplacez <INPUT_FILE> et les autres espaces r√©serv√©s avant l‚Äôex√©cution.",
    "pose_generate_cli_btn": "üß∞ G√©n√©rer la CLI Pose",
    "pose_cli_command_label": "Commande CLI Pose",
    "pose_cli_command_info": "Commande mod√®le pour l‚Äôestimation de pose",
    "fbx_cli_generator_title": "CLI de G√©n√©ration FBX",
    "fbx_cli_generator_info": "Cr√©e un mod√®le de commande pour g√©n√©rer un FBX. Remplacez <INPUT_FILE> et les autres espaces r√©serv√©s avant l‚Äôex√©cution.",
    "fbx_generate_cli_btn": "üß∞ G√©n√©rer la CLI FBX",
    "fbx_cli_command_label": "Commande CLI FBX",
    "fbx_cli_command_info": "Commande mod√®le pour la g√©n√©ration FBX",
    "refinement": {
      "title": "Raffinement",
      "enabled": "Activ√©",
      "enabled_info": "Activer le traitement de raffinement (se produit apr√®s la g√©n√©ration)",
      "load_config": "Charger la Configuration",
      "load_config_info": "T√©l√©chargez un fichier de configuration JSON",
      "save_config": "Enregistrer la Configuration",
      "save_config_info": "T√©l√©charger la configuration actuelle en JSON",
      "save_config_btn": "Enregistrer la Configuration",
      "global_settings": "Param√®tres Globaux de Raffinement",
      "sections": {
        "root": "Racine",
        "hands": "Mains",
        "fingers": "Doigts",
        "head": "T√™te",
        "legs": "Jambes",
        "arms": "Bras",
        "default": "Par D√©faut"
      },
      "max_pos_speed": "Vitesse Positionnelle Maximale",
      "max_pos_speed_info": "Vitesse positionnelle maximale (unit√©s/sec) pour la d√©tection de pics",
      "max_pos_accel": "Acc√©l√©ration Positionnelle Maximale",
      "max_pos_accel_info": "Acc√©l√©ration positionnelle maximale (unit√©s/sec¬≤) pour la d√©tection de pics",
      "max_ang_speed_deg": "Vitesse Angulaire Maximale (Degr√©s)",
      "max_ang_speed_deg_info": "Vitesse angulaire maximale (deg/sec) pour la d√©tection de pics",
      "max_ang_accel_deg": "Acc√©l√©ration Angulaire Maximale (Degr√©s)",
      "max_ang_accel_deg_info": "Acc√©l√©ration angulaire maximale (deg/sec¬≤) pour la d√©tection de pics",
      "method": "M√©thode",
      "method_info": "M√©thode de filtre de lissage",
      "method_one_euro": "One Euro",
      "method_ema": "EMA",
      "method_butterworth": "Butterworth",
      "cutoff_hz": "Fr√©quence de Coupure (Hz)",
      "cutoff_hz_info": "Fr√©quence de coupure pour les filtres EMA/Butterworth",
      "one_euro_min_cutoff": "Coupure Minimale One Euro (Hz)",
      "one_euro_min_cutoff_info": "Fr√©quence de coupure minimale pour le filtre One Euro",
      "one_euro_beta": "B√™ta One Euro",
      "one_euro_beta_info": "Coefficient de vitesse pour le filtre One Euro",
      "one_euro_d_cutoff": "Coupure D√©riv√©e One Euro (Hz)",
      "one_euro_d_cutoff_info": "Fr√©quence de coupure d√©riv√©e pour le filtre One Euro",
      "root_cutoff_xy_hz": "Coupure Racine XY (Hz)",
      "root_cutoff_xy_hz_info": "Fr√©quence de coupure pour le mouvement de racine horizontal (XY)",
      "root_cutoff_z_hz": "Coupure Racine Z (Hz)",
      "root_cutoff_z_hz_info": "Fr√©quence de coupure pour le mouvement de racine vertical (Z)",
      "interpolate_missing_keyframes": "Interpoler les images cl√©s manquantes",
      "interpolate_missing_keyframes_info": "Lorsqu'elle est activ√©e, les images manquantes (o√π aucune personne n'a √©t√© d√©tect√©e) seront interpol√©es en utilisant slerp pour les rotations et l'interpolation lin√©aire pour les vecteurs. Lorsqu'elle est d√©sactiv√©e, les images manquantes sont ignor√©es pendant le raffinement.",
      "use_foot_planting": "Utiliser le Plantage de Pied",
      "use_foot_planting_info": "Activer le plantage de pied pour ajuster le mouvement de racine en fonction du contact du pied, r√©duisant les saccades et cr√©ant un mouvement de marche/course plus naturel",
      "foot_planting": {
        "title": "Plantage de Pied",
        "foot_contact_velocity_threshold": "Seuil de Vitesse de Contact du Pied (m/s)",
        "foot_contact_velocity_threshold_info": "Le pied est consid√©r√© comme 'plant√©' si sa vitesse est inf√©rieure √† ce seuil",
        "foot_contact_min_height": "Hauteur Minimale de Contact du Pied (m)",
        "foot_contact_min_height_info": "Le pied doit √™tre en dessous de cette hauteur (coordonn√©e Y) pour √™tre consid√©r√© en contact",
        "contact_smoothing_window": "Fen√™tre de Lissage de Contact",
        "contact_smoothing_window_info": "Nombre d'images √† utiliser pour lisser la d√©tection de contact (r√©duit le scintillement)",
        "blend_factor": "Facteur de M√©lange",
        "blend_factor_info": "Combien m√©langer l'ajustement de racine bas√© sur le pied avec le mouvement de racine original (0-1, plus √©lev√© = plus d'ajustement)",
        "root_smoothing_window": "Fen√™tre de Lissage de Racine",
        "root_smoothing_window_info": "Nombre d'images √† utiliser pour lisser le mouvement de racine ajust√©",
        "use_mid_foot": "Utiliser le Milieu du Pied",
        "use_mid_foot_info": "Utiliser le milieu du pied (moyenne du talon/orteils) au lieu de la cheville pour la position du pied"
      }
    }
  },
  "progress": {
    "processing_keyframes": "üì¶ Traitement des images cl√©s...",
    "processing_person": "üì¶ Traitement de la personne...",
    "reexporting": "üîÑ R√©-exportation depuis les r√©sultats enregistr√©s...",
    "applying_refinement": "Application du raffinement aux r√©sultats d'estimation...",
    "preparing_fbx_data": "Pr√©paration des donn√©es FBX...",
    "preprocessing_complete": "Pr√©-traitement termin√©",
    "refining_person": "Raffinement de la personne {person_index} sur {total_people}",
    "refinement_complete": "Raffinement termin√©",
    "applying_poses": "Application des poses : {frame_num}/{total_frames}",
    "estimating_frame": "Estimation de l'image {frame_index} sur {total_frames}"
  },
  "errors": {
    "error_occurred": "Une erreur s'est produite ({error_type}): {error_msg}",
    "error_occurred_no_msg": "Une erreur s'est produite : {error_type}",
    "bbox_file_required": "Le fichier BBOX doit √™tre fourni lorsque 'utiliser bbox' est activ√©",
    "num_people_required": "Le nombre de personnes doit √™tre sup√©rieur √† 0",
    "camera_intrinsics_required": "Le fichier d'intrins√®ques de cam√©ra doit √™tre fourni lorsque la m√©thode FOV est 'Fichier'",
    "fov_estimator_required": "L'estimateur FOV doit √™tre charg√© pour utiliser la m√©thode '√âchantillon'. Veuillez vous assurer que l'estimateur FOV est initialis√©.",
    "pose_json_file_required": "Veuillez fournir un fichier JSON d'estimation de pose"
  }
}
